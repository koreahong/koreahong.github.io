---
layout: post
title: '누구나 파이썬 통계학'
subtitle: '통계기초 with Python'
categories: book
tags : study
comments: False
---

> 파이썬으로 통계기초 배우기

# 1. 데이터

## 1.1 데이터의 크기
	- .shape : 행, 열 개수
## 1.2 변수의 종류
	1.2.1 질적 변수와 양적변수
		- 질적변수 : 설문조사 등 종류를 구별하기 위한 변수
		- 양적변수 : 시험 점수나 신장과 같이 양을 표현하는 변수
	1.2.2 척도 수준
		- 명의 척도 : 구별하는 것
		- 순서 척도 : 순서관계, 대소관계, 차이 x
		- 간격 척도 : 대소관계, 차이 O, 비 X
		- 비례 척도 : 대소관계, 차이 O , 비 O, 절대 0이 존재함
	1.2.3 이산형 변수와 연속형 변수
		- 이산형 변수 : 하나하나의 값을 취하는 변수, 인접한 숫자 사이에 값이 존재하지 않음
		- 연속형 변수 : 연속적인 값을 취할 수 있는 변수

# 2. 1차원 데이터 정리
## 2.1 데이터 중심의 지표(기술통계)
	- 2.1.1 평균값
		- 전체합 / 관측 수
		- 이상치에 민감함
		- np.mean(), df.mean()
	2.1.2 중앙값
		- 데이터를 크기 순서대로 나열할때 정확하게 중앙에 위치한 값
		- 홀수 : n+1 / 2
		- 짝수 : n + 2 / 2
		- 이상치에 덜 민감함
		- np.median(), df.median()
	2.1.3 최빈값
		- 데이터에서 가장 많이 나타나는 값
		- pd.Series().mode()
		- from collections import Counter /  Counter()

## 2.2 데이터의 산포도 지표
	2.2.1 분산과 표준편차
		- 편차 : 각 데이터가 평균으로부터 어느 정도 떨어져 있는가를 나타내는 지표
		- 분산 : 편차 제곱 평균, 편차의 합은 0이기 때문에 제곱하고 평균을 해줌
		- 분산 => np.var(ddof = 1 or 0)
		- 표준편차 : 데이터와 동일한 단위를 쓰는 산포도의 지표
		- 표준편차 => np.std(ddof = 1 or 0)
	2.2.2 범위와 사분위 범위
		- 범위 : 최댓값과 최솟값만으로 산포도를 봄
		- 범위 => np.max() - np.min()
		- 사분위 범위 : 25% 50% 75%에 위치하는 값에 주목
		- IQR = Q3 - Q1
		- 사분위 => np.percentile(data, 사분위), .describe()

## 2.3 데이터의 정규화
	- *다른 지표에 의존하지 않고 데이터의 상대적인 위치 관계를 알 수 있는 지표*
	- 데이터를 통일된 지표로 변환하는 것
	
	2.3.1 표준화
		- 데이터에서 평균을 빼고 표준편차로 나누는 작업, = Z점수, = 표준화 변량
		- xi - xbar / S
	2.3.2 편찻값
		- 50 + 10 * xi - xbar / S

## 2.4 1차원 데이터의 시각화
	2.4.1 도수분포표
		- *데이터의 분포 상태를 세부적으로 보고 싶을 때 사용*
		- 계급 : 구간
		- 도수 : 구간별 관측개수
		- 계급폭 : 각 구간의 폭
		- 계급수 : 계급의 수
		- 계급값 : 계급의 중앙값
		- 상대도수 : 해당 도수 / 전체도수합
		- 누적 상대도수 => np.cumsum()
	2.4.2 히스토그램
		- 도수분포표를 막대그래프로 나타낸 것
		- => .hist(data, bins=, range=)
	2.4.3 상자그림
		- => .barplot(data, labels=[])

# 3. 2차원 데이터 정리
## 3.1 두 데이터 사이의 관계를 나타내는 지표
	3.1.1 공분산
		- *데이터의 관계성을 수치화*
		- 부호를 붙인 면적의 평균은 상관의 지표가 됨
		- => np.cov(data1, data2, ddof= 1 or 2)
	3.1.2 상관계수
		- 단위에 의존하지 않는 상관을 나타내는 지표
		- -1 ~ 1사이에 값을 가짐
		- => np.corrcoef(data1, data2), df.corr()

## 3.2 2차원 데이터의 시각화
	3.2.1 산점도 
		- => .scatter(data1, data2)
	3.2.2 회귀직선
		- => .np.polyfit(data1, data2, 1) ->  .np.poly1d(polyfit) -> x좌표 구하기(np.linspace(최대, 최소)) -> y좌표 구하기(poly_1d(x좌표))  
	3.2.3 히트맵
		- 히스토그램의 2차원 버전
		- => .hist2d(data1, data2, bins=, range=)

## 3.3 앤스컴의 예
	- 지표가 모두 같다고 같은 데이터그룹으로 취급하면 안됨!
	- 반드시 그래프를 그려 분포를 확인해야 함

# 4. 추측통계의 기본

## 4.1 모집단과 표본
	- 모집단 : 추측하고 싶은 관측 대상 전체
	- 표본 : 추측에 사용하는 관측 대상의 일부분
	- 모수 : 모집단의 통계치
	- 표본통계량 : 표본의 통계치

	4.1.1 표본추출 방법
		- 편향되지 않게 추출하는 것이 중요
		- 무작위추출 : 임의로 표본 추출
		- 복원추출, 비복원추출
		- => np.random.choice()
		- 재현성 유지를 위해 seed()를 사용

## 4.2 확률모형
	4.2.1 확률의 기본
		- 확률변수 : 취하는 갑소가 그 값이 나올 확률이 결정되어 있는 것
		- 시행 : 확률변수의 결과를 관측하는 것
		- 실현값 : 시행에 의해 관측되는 값
		- 사건 : 시행 결과로 나타날 수 있는 일
		- 근원사건 : 더 세부적으로 분해할 수 없는 사건
		- 상호배반 : 각 사건이 동시에는 일어날 수 없다는 뜻

## 4.3 추측통계의 확률
	- 시행횟수를 늘리면 늘릴 수록 표본의 산포는 모평균을 중심으로 분포함
	- 무작위추출에 의한 표본평균으로 모평균을 추측할 수 있는 근거

# 5. 이산형 확률변수

## 5.1 1차원 이산형 확률변수
	5.1.1 1차원 이산형 확률변수의 정의
		- 이산형 확률변수는 취할 수 있는 값이 이산적인 확률변수임
		- 확률질량함수, =확률함수, 확률변수가 취할 수 있는 값을 함수로 표현한 것
		- 확률분포 : 취할 수 있는 값과 그 확률의 구체적인 대응
		- 확률의 성질
			- 확률은 절대적으로 0이상
			- 확률의 총합은 1
		- 확률변수의 변환 : 확률변수를 변환시켜도 확률변수를 따른다	
	
	5.1.2 1차원 이산형 확률변수의 지표
		- 기댓값 : 확률변수의 평균은 확률변수의 중심을 나타내는 지표, *확률변수를 몇번이나 시행하여 얻어진 실현값의 평균*
		- 기댓값은 선형성을 가지고 있어서 변환한 확률변수의 기댓값을 변환하기전 확률변수의 기댓값으로 구할 수 있다
		- 분산 : 데이터의 분사과 마찬가지로 산포도를 나타내는 지표

## 5.2 2차원 이산형 확률변수
	5.2.1 2차원 이산형 확률변수의 정의
		- 결합확률분포 : 확률변수 (X,Y) 움직임을 동시에 고려한 분포
		- 주변확률분포 : 개별 확률변수에만 관심이 있을때, fx(x)는 fxy에서 y가 취할 수 있는 값 모두를 대입한 다음 모두 더한 값

# 6. 이산형 확률분포
	- 베르누이분포 : 한번 시행했을대 성공 혹은 실패할 확률
	- 이항분포 : 베르누이 시행을 n번했을때 성공 혹은 실패할 확률
	- 기하분포 : 베르누이 시행에서 처음 성공할 때까지 반혹한 시행 횟수가 따르는 분포
	- 포아송분포 : 임의의 사건이 단위 시간당 발생하는 건수가 따르는 확률분포, 하루에 평균 2건의 교통사고가 발생하는 지역에서, 교통사고가 안날 확률

# 8. 연속형 확률분포
	- 정규분포
		- 성질 : 변환한 확률변수도 정규분포를 따름
		- 파라미터 : 뮤, 시그마
		- 정규화 -> 표준정규분포 -> (0,1)를 따름
	- 지수분포
		- 어떤 사건이 발생하는 간격이 따르는 분포, 교통사고가 일어난 뒤 3일 이내에 또 교통사고가 일어날 확률
	- 카이제곱분포
		- 분산의 구간추정이나 독립성 검정에서 사용
	- t분포
		- 정규분포에서 모평균의 구간추정 등에 사용
		- 특징
			- 좌우대칭인 분포
			- 표준정규분포보다 양쪽 끝이 두꺼움
			- 자유도가 커지면 표준정규분포에 가까워짐
	- f분포
		- 분산분석 등에서 사용
		- 특징
			- 좌우비대칭, 왼쪽으로 치우치고 오른쪽으로 넓어지는 분포
			- 분포의 정점은 1에 가깝습니다

# 9. 독립동일분포
	- 서로 독립이고 각각 동일한 확률분포를 따르는 다차원 확률변수

## 9.1 독립성
	9.1.1 독립성의 정의
		- 2개 이상의 확률변수가 서로 영향을 끼치지 않으며 관계가 없음
		- 확률변수가 독립일때 결합확률은 주변확률의 곱으로 작성할 수 있음
	9.1.2 독립성과 무상관성
		- 무상관성보다 독립성이 강한개념
		- 무상관이라고 해서 서로 독립적인 것은 아님

## 9.3 표본평균의 분포
	- 중심극한정리 : 원래 부포가 뭐였든 간에, 표본평균의 분포는 정규분포에 가까워짐
	- 대수의 법칙 : 표본 크기를 키우면 표본평균은 모평균에 수렴

# 10. 통계적 추청

## 10.1 점추정
	10.1.1 모평균의 점추정
		- 불편성 : 추정량의 기댓값이 추측하려는 모수가 되는 성질
		- 불편추정량 : 불편성을 가진 추정량
		- 표본평균이 모평균을 잘 추정할 수 있는 근거

		- 일치성 : 표본크기를 증가시키면 추측하기 원하는 모수에 수렴해가는 성질
		- 일치추정량 : 일치성을 가진 추정량

		- 불편분산 : 모분산의 불편추정량이 되는 표본 통계량, 자유도 사용, **표본분산은 표본개수대로 나누지만 불편분산은 자유도로 나눔**

## 10.2 구간추정
	10.2.1 모분산을 알고 있는 경우
		- 표준오차 : 모집단이 정규분포를 따른다는 가정하에 추정량의 표준편차
		- 신뢰구간 : 표본을 통해서 모평균,모분산을 구간추정 하는 것
		- 95% 신뢰구간 의미 : 동일한 방법으로 수차례 표본추출하여 구간추정을 하면, 그중에 95% 구간추정에는 모평균이 포함되어 있다는 뜻

	***모집단의 분포를 모를때***
		- 중심극한정리를 통해 표본평균은 정규분포를 따름
		- 표준정규분포로 변환

# 11. 통계적 가설검정

## 11.1 통계적 가설검정
	11.1.1 통계적 가설검정의 기본
		- 대립가설, 귀무가설, 기각역, 채택역, 유의수준, 임계값, 검정통계량, p값
	11.1.2 단측검정과 양측검정
		- 단측검정 : ~이상, ~이하일 것이다
		- 양측검정 : 같다, 아니다
	11.1,3 두 가지 오류
		- 제1종 오류 : 귀무가설이 옳을때, 귀무가설을 기각하는 오류, 오탐 => 알파 (유의수준)
		- 제2종 오류 : 대립가설이 옳을때, 귀무가설을 채택하는 오류, 미탐 => 베타, 1-베타 = 검정력

## 11.2 기본적인 가설검정
	- 모평균 검정, 모분산을 알고 있는 경우 -> 정규분포
	- 모분산 검정 -> 카이제곱분포
	- 모평균 검정, 모분산을 모르고 있는 경우 -> t분포 검정

## 11.3 2표본 가설검정
	- 대응비교 t검정 / 전-후와 같이 데이터가 대응될때 사용
	- 독립비교 t검정 / 대응하지 않고 독립된 2표본 모집단 검정, 평균값 차이에 대한 검정 / 자유도는 웰치의 방법
	- 윌콕슨의 부호순위검정 : 대응표본에서 차이에 정규분포를 가정할 수 없는 경우, 중앙값의 차이에 대한 검정
	   차이에 편향이 있을수록 마이너스,플로스에도 편향이 생기고, 검정통계량은 작은 값이 됩니다
	- 만 위트니의 u검정 : 데이터가 없는 2표본 모집단에 정규분포를 가정할 수 없는 경우, 중앙값의 차이에 대한 검정
	- 카이제곱검정 : X,Y가 도립이 아니다라는 검정

# 12. 회귀분석
	- 회귀분석의 목적은 복잡한 현상을 사람이 이해할 수 있을 정도의 간단한 구조로 충분히 설명할 수 있는 모형을 찾는 것이다

## 12.1 단순회귀모형
	- 설명변수, 반응변수
	- 설명변수가 하나인 것이 단순회귀모형
	
	12.1.1 회귀분석에서의 가설
		- 오차항 : 예측할 수 없는 부분. 기본적인 관계는 직선상에 있다고 생각하고, 다른 요인에 관해서는 예측할 수 없는 확률적인 것이라고 생각. 
		- 설명변수가 확률변수는 아니다 -> 고정된 값
		- 오차는 서로 독립이고 (0,시그마제곱)을 따름

	12.1.2 statsmodels 사용한 회귀분석
		-=> formular = ' ~ '
		-=> result = smf.ols(formula, df).fit()
		-=> result.summary()

	12.1.3 회귀계수
		- 점추정 : 예측값, 잔차제곱합이 작은 직선
		- 수많은 직전숭 회귀직선이 데이터에 대해 잔차제곱합을 가장 작게 하는 직선
		- 위 방법을 최소제곱법이라고 함

		- 구간추정 

		- t검정으로 계수가 유의미한지 확인

## 12.2 다중회귀모형
	- 설명변수가 2개 이상인 모형
	
	
## 12.3 모형의 선택
	- 좋은모형 기준 : 적합력, 예측력이 높은것, 그 중 예측력이 높은 것, 적합력은 과적합이 될 수 있는 경우가 있음
	- 적합력 판단 : 잔차제곱합 - 동일한 모형 중에서 상대적으로만 사용
	- 결정계수 : 다른 모형끼리 비교할 때 사용할 수 있는 지표
		- 1 - 잔차변동/총변동 = 단순회귀에서는 상관계수 제곱과 일치함
		- 별 의미 없는 변수가 들어간다 해도 설명변수가 증가하면 결정계수가 증가함
	- 조정결정계수 : 변동에 자유도를 조정해서 의미 없는 변수의 영향력 제거

	- f검정 : 모형 전체에 적용, 베타계수 중 하나는 0이 아니다 = X중 하나는 적어도 y와 연관이 있음
		- 모형의 적합도가 좋을수록 잔차변동보다 회귀변동이 커지는 것을 이용
		- 분산의 비 이용 : 분산분석

	12.3.4 최대로그우도와 AIC
		- 우도 : 어떤 관측값을 얻을 확률
		- 우도함수 -> 확률 p를 알지 못하는 상황에서 특정한 결과를 얻을 수 있는 우도는? 
		- 우도함수가 최대가 되는 p값 = 최우추정량 = 최우추정값, 이와 같은 방법을 최우추정법
		- 로그우도 : 확률은 곱하면 곱할수록 작아지기 때문에 로그를 붙여 사용
		- 최대로그우도 : 우도함수가 최대로 될 때 로그우도함수최대

		- AIC : 모형의 복잡도와 데이터에 대한 적합도의 균형을 잡는 지표
			- -2 * 최대로그우도 + 2 * 회귀계수의 수
			- 값이 작을수록 모형의 예측 정확도가 좋음

		- BIC
			- -2 * 최대로그우도 + logn * 회귀계수의 수
			- 값이 작을수록 모형의 예측 정확도가 좋음

## 12.4 모형의 타당성
	12.4.1 정규성 검정
		- 잔차가 정규분포를 따르고 있는지
		- 왜도 + 0 - 
		- 첨도 + 3 -
