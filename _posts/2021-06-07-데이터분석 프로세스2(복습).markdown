---
layout: post
title: '데이터분석 프로세스2(복습)'
subtitle: '파이썬 머신러닝 완벽 가이드 발췌'
categories: Data_Analysis
tags : theory
comments: False
---

> 데이터수집부터 모델평가까지 놓친 내용

# 검증
- 그리드 서치 알고리즘과 cross_val_score() 차이
	- 그리드서치 알고리즘 : stratified 적용, 하이퍼 파라미터 최적화 + 교차검증
	- cross_val_score() : 결과값만 간단하게 보고 싶을 때 사용

#데이터 전처리
- 문자형 데이터 인코딩
	- 레이블 이코딩 : 숫자의 크고 작음이 결과 값에 반영, 선형 회귀에는 치명적
	- 원핫 인코딩 : 문자형이 숫자형으로 전환된 뒤 사용가능, 레이블 인코딩 -> 원핫 인코딩, 해당 과정을 판다스의 get_dummies로 한번에 가능

- 피쳐 스케일링
	- 표준화 : 표준정규분포로 변환
	- 정규화 : 최대최소정규화, 가우시안 분포를 따르지 않을 때 사용, 0~1 사이 값을 가짐

# 평가
- 균형잡힌 데이터 : 정확도
- 비균형 데이터 : f1score(조화평균)
	- 사용이유 : 두개의 값을 모두 고려하기 때문에 다소 편향되지 안흔ㄴ 값을 산출함

- 정밀도 : 예측 T에서 실제 T, TP / (TP + FP), 실제 F인데 T로 잘못 판단하면 큰일 나는 경우
- 재현율 : 실제 T에서 예측 T, TP / (TP + FN), 실제 T인데 F로 잘못 판단하면 큰일 나는 경우 
	- 보통 재현율이 상대적으로 중요한 지표
- roc 곡선 : FPR에 따른 TPR 변화 확인


#분류
- 결정트리 기반 : 지니계수, 정보이득(1-엔트로피), 높을 수록 균일도가 높음, 트리생성 기준
- 특징 
	- 직관적임
	- 균일도로 인해 피쳐 스케일링이 큰 영향이 없음
	- 과적합 발생, 정확도 떨어짐 => 하이퍼 파라미터로 트리규제
		- 단점 : 과적합 방지를 위해 규제할 파라미터가 많다

# 앙상블
- 대부분 동일한 알고리즘을 결합
- 목표 : 단일 분류기의 예측결과를 결합하여 더 좋은 결과를 얻는다

- 배깅 : 부트스트래핑으로 추출된 데이터를 학습 후 보팅으로 최종 결과 산출
- 부스팅 : 이전 분류기의 잘못예측한 데이터에 가중치를 부여하여 학습과 예측진행
- 스태킹 : 앙상블의 앙상블, 최종 분류된 분류기들을 합침

- 보팅과 스태킹은 다른 알고리즘 기반
- 배깅과 부스팅은 대부분 결정트리 기반

# XGBoost
- 과적합 규제 기능 자체적으로 있음

# LightGBM
- 빠름, 데이터가 적으면 과적합될 가능성이 높음

# 튜닝
- 파라미터를 여러 그룹으로 나뉜뒤 순차적으로 최적화 진행

# 스태킹앙상블
- 기본 스태킹 모델은 과적합의 우려가 있음
- 이를 해결하기 위해서 CV 세트기반 스태킹 앙상블 사용, 개별 모델로 새로운 학습데이터, 테스트 데이터를 만듬

# 회귀
- 편향,분산 트레이드 오프 관계
	- alpha 값을 통해 균형을 맞춰야 함, Min(RSS(w))+alpha*||W||2

# 로지스틱 회귀
- 시그모이드 함수 최적선을 찾음

# 회귀 파라미터
- 회귀계수가 높은 피처의 이상치 데이터 처리가 중요

# 차원축소
- 차원축소를 통해 더 데이터를 잘 설명할 수 있는 잠재적인 요소 추출

# LDA
- 지도학습임

# 군집화
- 분류와 차이점
	- 데이터 내의 의미 부여
	- 동일 그룹간 세분화
	- 다른 부류와 합쳐 더 넓은 군집화 가능

# 추천시스템
- 콘텐츠 기반 필터림
- 협업 필터링
	- 최근접 이웃
	- 잠재요인 : 행렬분해 / 경사하강법 사용,