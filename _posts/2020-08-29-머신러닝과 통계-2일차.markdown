---
layout: post
title: '[1일차]머신러닝과 통계'
subtitle: '[1일차]머신러닝과 통계 용어 및 비교'
categories: book
tags : study
comments: False
---
> 1일차 공부정리

# 1장 : 모델 구축과 검증을 위한 통계 용어

## 통계 / 모델 구축과 검증을 위한 용어

### 통계
 - 기술 통계학 : `자료 요약` (빈도, 퍼센티지 등)
 - 추론 통계학 : 표본을 통해 `모집단에 대한 결론을 유추` (가설 검정, 상관관계 등)
 - `통계모델은 가정과 그와 상응하는 확률분포로 이루어져 있음`
 
### 통계에서 사용되는 용어
 - 모집단 : 관측하려는 대상 전체
 - 표본 : 모집단의 부분집합
 - 매개변수 : `모집단에 관해 계산한 모든 척도
 - 통계량 : `표본`에 관해 계산한 모든 척도
 - 평균 : 산술평균을 의미함. 데이터의 내의 위치값.  
            산술평균은 특이값에 민감하기 때문에 로버스트한 가중평균이나 중간값을 대신하여  
	사용하는 경우가 있음
 - 중간값 : 데이터의 중간 지점.
 - 최빈값 : 데이터 중 가장 비번하게 반복되는횟수
 - 변량 : 산포는 데이터의 변량을 의미하고 데이터 변수가 부적합한 값을 갖는지 측정함.  
산포는 데이터들이 평균으로부터 얼마나 떨어져 있는지에 관한 정보를 제공함.
+ 범위 : 최댓값과 최솟값의 차이를 의미함.
+ 분산 : 평균과의 차이를 제곱한 값들의 평균으로, 제곱한 이유는 상쇄되는 것을 방지하기 위함.
+ 표준편차 : 분산에 제곱근을 적용함으로써 제곱한 차원이 아닌 원래 변수와 같은 차원에서 산포를 측정할 수 있다.
+ 분위수 : 데이터를 동리한 조각들로 나눈 것.
+ ICR범위 : 1사분위와 3사분위의 차이를 의미함. `데이터 중 이상값을 찾아낸는 데 효과적임`.
 - 가설설정 : 표본을 통해 모집단을 추론하는 과정. 귀무가설과 대립가설을 통해 검정함.  
	  + P값은 귀무가설이 옳다는 전제하에 극단적인 통계값이 관측될 확률  
	  + 1종오류 : 참인 귀무가설을 기각  
	  + 2종오류 : 거짓인 귀무가설을 수용
 - 정규분포 : 가장 일반적인 확률분포. 기존 많은 통계학적 바탕이 정규분포에 근간함.
 - 카이제곱검정 : `범주형 데이터의 통계 분석`에 가장 보편적으로 쓰이는 검정  
		`두 변수 사이에 통계적 상관성이 존재하는지를 판단`함.
 - 아노바 : `둘 이상 모집단의 평균이 서로 동일`한지 테스트함.  
	  요인의 중요도를 평가함
 - 혼동행렬 : 예측값이 얼마나 정확히 예측했는지 보여주는 행렬이다.

|       | `예상 : 예` | `예상 : 아니오` |
| ---------- | ------------ | ----------- |
| `실제 : 예` | TP | FN |                                                                                                                                                  
| `실제 : 아니오` | FP | TN |
                                                                                                                                                  
+ 정밀도 : 예로 예측했을 때의 정답률, TP / (TP + FN)
+ 재현율 / 민감도 : 실제 참인 것 중 참으로 예측한 비율, TP/(TP + FN)
+ F1 점수 : F1 점수는 정밀도와 재현율의 조화평균  
정밀도와 재현율 모두 밸런스가 맞는지 확인하는 지표

+ 특이성 : 실제 거짓 중 참이라고 한 비율, TN/(TN + FP)
+ ROC(곡선하 면적) : 1 - 특이성 그래프  
참 긍정률과 거짓 부정률 사이를 표현 
 - R제곱 : 만들어진 모델이 대상이 되는 데이터를 얼마나 표현하는지 비율로 보여주는 지표
 - 수정 R-제곱 : R제곱과 동일하나, 새로운 변수가 추가되면 강한 상관관계를 갖지 않는 한 일정 점수를 감점하는 것을 추가함.  
`선형 회귀 품질을 평가하는 핵심척도`
 - 최대 우도 추정 : 과거일을 통해 앞으로의 일을 예측하는 기법(추후에 자세히 설명)
 - 엔트로피 : `모델의 불순도`를 측정  
균질 1 <--> 0 비균질  
엔트로피값이 낮을 수록 더 잘 분리함.
 - 정보이득 : 관축값을 분할할 때 예상 엔트로피 감소를 의미.  
정보이득 : 부모 노드의 엔트로피 - sum(가중값 % * 자식 노드의 엔트로피)  
가중값 % = 특정 자식 노드의 관측값 수 / 모든 자식 노드의 관측값 수
 - 지니 : `오분류를 측정`하는 도구  
`다분류 뷴류기에 적용`
`엔트로피와 거의 동일하지만 훨씬 더 빠름`
 - 분산과 편향의 트레이드 오프  
+ `편향오류는 기본 학습 알고리즘의 잘못된 가정에서 비롯됨`
`높은 편향값`은 데이터와 결과물의 관계를 놓치제 하는 `과소 적합 문제를 초래`함.  
모델 예시 : 로지스틱, 선형회귀  
문제점 : `모델 적합화가 단순히 직선만으로 이뤄지므로 기본 데이터를 잘 근사하지 못하는 한계를 가짐`
+ `분산오류는 모델 적합화의 ㅂㄴ화에 관한 민감도에서 기인함`  
높은 분산의 경우는 `과적합 문제를 일으킴`  
모델 예시 : 의사결정 트리  
문제점 : `모델이 너무 구불구불한 곡선으로 적합화된 경우 데이터에 민감하여 정확하지 못하는 한계를 가짐`  

위의 두 문제는 `앙상블 기법`을 활용해 편향과 분산을 모두 해결할 수 있음.  

## 머신러닝 / 모델 구축과 검증을 위한 용어

### 머신러닝
 - 데이터로부터 경험을 축적해 스스로 학습할 수 있는 모델을 연구하는 분야
 - 머신러닝의 `목표`는 관측된 `패턴을 일반화`하거나 `주어진 예제를 통해 새로운 규칙을 생성`해내는 것

### 머신러닝에서 사용되는 용어
 - 기울기 하강법 : 목접함수를 최소화하는데 사용됨.  
최소화 과정은 목적 함수의 경사와 반대 방향으로 매개변숫값을 지속적으로 갱신하면서 이뤄짐.
 - 확률적 기울기 하강법 : 각 반복 때마다 하나의 관측값만 선택해 갱신함.  
가장 빠른 방법이나 수렴과정에 많은 잡음이 끼어듬.
 - 교차검증 : 모델의 안정성을 추구하는 방법.  
1. 데이터를 동일한 조각으로 분할  
2. 한 조각만을 제외하고 나머지 모든 부분에 관해 훈련  
3. 제외된 조각으로 모델 성능을 평가.

 - 그리드 검색 : 머신 러닝에서 `최적합을 찾기 위해 초매개변수를 튜닝`하는 기법.

### 머신러닝 모델 개관
 - 지도학습 : `목표 변수와 다른 변수 간의 관계를 머신이 학습하도록 가르치는 방법`  
모델 예시 : 분류문제, 회귀문제, 렌덤포레스트 등
- 비지도 학습 : `지도나 목표 변수를 설정하는 과정 없이 알고리즘이 스스로 학습하는 방법`  
데이터 사이의 숨은 패턴이나 관계를 찾는 문제.
 - 강화학습 : 머신이나 에이전트가 주변 환경의 피드백으로부터 행동을 학습하는 방법.