---
layout: post
title: '[3일차]머신러닝과 통계'
subtitle: '[3일차]로지스틱회귀와 랜덤포레스트 비교 / 모델의 근본으로의 차이(통계학 머신러닝)'
categories: book
tags : study
comments: False
---
> 3일차 공부정리

# 3장 : 로지스틱회귀와 랜덤포레스트 비교 / 모델의 근본으로의 차이(통계학 머신러닝)

## 로지스틱회귀와 랜덤포레스트 비교 / 모델의 근본으로의 차이(통계학 머신러닝)

### 3장 구조

#### 로지스틱회귀(통계 근본)와 랜덤포레스트(머신러닝 근본) 비교

 - **중요한 변수는 어느 모델이나 중요한 역할을 한다**

 - 로지스틱회귀
 + 개요 : 개별 매개변수에 관해 우도를 최대화함으로써 매개변수를 찾으려고 하는 것
 	+ **최대 우도 추정** : 관측값이 주어졌을 때 모델의 매개변수들 중 그 관측값을 발생시켰을 가능성이 
가장 높은 매개변숫값들을 거꾸로 찾아내는 것  
=> 사건이 발생할 가능성 p와 사건이 미발생할 가능성 (1-p)를 최대화하는 매개변수들을 찾는 것
 + 방법론 : 종속변수를 독립변수에 관한 승산비(오즈비)로 변환한 후 최대 우도 추정 기법을 적용하여 어떤 사건이 발생할 확률을 추정한다.
이 과정에서 로그변환하여 선형문제로 바꿔 문제를 풀기 쉬운 형태로 변환한다.
 + 용어  
 	+ 정보 가치 : 이 값은 변수를 모델에 포함시킬지 여부를 판단하는 전처리 필터링 단계에서 유용함.  
업계에서는 **`정보가치`**를 주로 모델을 적합화하기 전 **`첫 단계에서 주요변수를 제거하는 데 사용함`**.  
 	+ AIC : 이 척도는 주어진 데이터 집합에 관해 통계 모델의 상대적 품질을 측정함.  
편향과 분산의 트레이드 오프인데 이는 모델내에 크게 유의미하지 않은 변수라도 일단 더 참여시키면 훈련의 정확도를 인위적으로 개선할 수 있다는 뜻임.  
다만, 훈련데이터에서 좋은 정확도를 얻을 수 있을지 몰라도 테스트 데이터에서는 정확도는 감소한다.
 	+ ROC 곡선 : 긍정가 부정 부류 사이의 트레이드 오프를 하며 전반적인 정확도를 높이는 값으로 선택해야 함.
 	+ 일치값 / c-통계량 : 전차 조합 가능한 쌍 중에서 이벤트가 발생하지 않은 쌍보다 이벤트가 발생한 쌍에 더 높은 확률값을 정확히 부여한 쌍의 비율.  
통상 0.7보다 높으면 실제 사용하기 좋은 모델로 간주함.
+ 순서
	+ 1. 제외 기준 및 적합-부적합 정의 완료  
2. 초기 데이터 준비 및 단일 변량 분석  
IV값을 활용하여 변수의 가치 파악  
3. 파생 / 더미 변수 생성  
이때 변수의 부류수보다 하나 적게 만든다. 똑같으면 불필요한 여분이 생기기 때문임.
4. 미세분류와 개략분류  
AIC, 다중공정성, P값을 통해 변수를 제거함.
5. 훈련 데이터 로지스틱 모델 적합화  
임계값 설정  
6. 테스트 데이터로 모델 평가  

 - 랜덤포레스트 자세히

 - 로지스틱회귀 랜덤포레스트 비교
 + 개요
 + 기반
 + 열선택
 + 데이터선택
 + 모델 구축 과정


